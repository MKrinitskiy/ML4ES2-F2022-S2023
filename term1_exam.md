# Список тем к зачету за 1 семестр.

#### Секция 1: Многослойная полносвязная искусственная нейронная сеть
1. Обобщенные линейные модели (GLM). Обобщенные аддитивные модели (GAM). Искусственная нейронная сеть как обобщение GAM.
2. Многослойная искусственная нейронная сеть как GAM. Многослойный перцептрон (MLP). Формула MLP. Представление MLP в качестве диаграммы.
3. MLP: формула, диаграмма. Функция активации: определение, виды. Слой: определение виды.
4. MLP: формула, диаграмма. Функции ошибки в различных задачах МО.

#### Секция 2: оптимизация глубоких ИНС
1. Оптимизация глубоких ИНС. Градиентная оптимизации, стохастическая градиентная оптимизация.
2. Градиентная оптимизация глубоких ИНС. Метод вычисления градиента по параметрам.
3. Градиентная оптимизация глубоких ИНС. Метод вычисления градиента по признаковому описанию.
4. Градиентная оптимизация глубоких ИНС. Метод вычисления градиента по скрытым представлениям.
5. Градиентная оптимизация глубоких ИНС. Диагностика процесса оптимизации.
6. Ландшафт функции потерь глубоких ИНС. Свойства ландшафта ф-ии потерь. Фрактальность ландшафта ф-ии потерь. Эффективный ландшафт функции потерь и отличие от истинного.
7. Ландшафт функции потерь глубоких ИНС. Свойства ландшафта ф-ии потерь. Эффективный ландшафт функции потерь и отличие от истинного. Внедрение шума в процес оптимизации. Преимущества и недостатки подхода зашумления.
8. Ландшафт функции потерь глубоких ИНС. Эффективный ландшафт функции потерь и отличие от истинного. Внедрение шума в процесс оптимизации: назначение; эффект, оказываемый на процесс оптимизации, диагностика эффекта.
9. Ландшафт функции потерь глубоких ИНС. Свойства ландшафта ф-ии потерь. Зависимость ландшафта ф-ии потерь от данных. Плоский и острый минимумы. Их преимущества и недостатки.
10. Градиентная оптимизация глубоких ИНС. Роль начального приближения и дисперсия активаций. Диагностика подходящего и неподходящего начальных приближений.
11. Градиентная оптимизация глубоких ИНС. Алгоритмы оптимизации, их назначение и свойства: SGD.
12. Градиентная оптимизация глубоких ИНС. Алгоритмы оптимизации, их назначение и свойства: AdaGrad.
13. Градиентная оптимизация глубоких ИНС. Алгоритмы оптимизации, их назначение и свойства: Momentum.
14. Градиентная оптимизация глубоких ИНС. Алгоритмы оптимизации, их назначение и свойства: Adam.
