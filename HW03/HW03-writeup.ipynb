{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №2.1 - автокодировщики для идентификации аномалий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ДЗ вам предстоит применить модель сврточного автокодировщика для идентификации аномалий в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого вам потребуется создать сверточный автокодировщик, обучить его и применить к тестовым данным.\n",
    "\n",
    "Основная идея фильтрации аномалий состоит в том, что экземпляры выборки, являющиеся аномалиями, сильно отличаются от всех остальных объектов. Кроме того, их мало по сранению с размером всей выборки.\n",
    "Этот набор факторов приводит к тому, что автокодировщик, обученный на данных тренировочной выборки, будет довольно плохо восстанавливать примеры-аномалии. То есть, значения функции потерь на таких примерах ожидается нетипично высоким."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эту ячейку следует выоплнять в окружении, в котором еще не установлены необходимые библиотеки. В подготовленном окружении эту ячейку можно пропустить.\n",
    "!pip3 install torch torchvision numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os, urllib\n",
    "\n",
    "from typing import Tuple, List, Type, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def md5(fname):\n",
    "    import hashlib\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def show_progress(block_num, block_size, total_size):\n",
    "    print(round(block_num * block_size / total_size *100,2), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие две ячейки предназначены для загрузки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_hash = '0a1db355c009f01ead98dcff6720fe3e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading MNIST data with outliers:\n",
      "MNIST data is valid\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./mnist_corrupted.npz'):\n",
    "    print('downloading MNIST data with outliers:')\n",
    "    urllib.request.urlretrieve(\"https://ml4es.ru/links/mnistcorrupted\", \"mnist_corrupted.npz\", show_progress)\n",
    "downloaded_mnist_data_hash = md5('./mnist_corrupted.npz')\n",
    "assert downloaded_mnist_data_hash == mnist_data_hash, 'Downloaded MNIST data is corrupt. Try downloading again.'\n",
    "print('MNIST data is valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свёрточный автокодировщик (convolutional autoencoder, CAE)\n",
    "\n",
    "Данными в этой задаче будут все так же набор рукописных цифр MNIST. Однако некоторые экземпляры тестовой выборки оказываются испорченными. Ваша цель - найти эти экземпляры в предположении, что они представляют собой аномалии.\n",
    "\n",
    "Данные MNIST с дефектами нужно скачать в виде файла по <a href=\"https://www.dropbox.com/s/r7mgjn83y9ygpzq/mnist_corrupted.npz\">ссылке</a>\n",
    "\n",
    "Прежде всего следует построить и обучить свёрточный автокодировщик.\n",
    "\n",
    ">Кодирующая часть автокодировщика (encoder, кодировщик) может состоять из сверточных слоев (convolutional layers) и слоев субдискретизации (pooling layers), но может быть и сложнее. Здесь предлагается применить ваши знания относительно возможной структуры сверточных сетей. Кодировщик, будучи обученным, позволяет извлечь скрытое представление (hidden representation, embeddings) входных примеров, содержащее достаточно информации для восстановления этих примеров декодером.\n",
    "\n",
    "> Декодер (decoder) может состоять из слоев типа **transpose convolution** и операций масштабирования (upsampling), но также, как и кодировщик, может быть сложнее. Декодер должен восстанавливать примеры, руководствуюясь их векторами скрытого представления.\n",
    "\n",
    "<img src='imgs/autoencoder_1.png' />\n",
    "\n",
    "### Скрытое представление (hidden representation, compressed representation)\n",
    "\n",
    "Скрытое представление может содержать семантически насыщенную информацию о входных примерах. С использованием этих данных можно проводить фильтрацию шума в примерах, восстанавливать сами примеры, и иногда даже проводить некоторые операции в семантическом пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предположении, что файл данных `mnist_corrupted.npz` загружен и находится в той же директории, что и этот нотбук, генераторы данных можно описать следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(x.astype(np.uint8))\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('./mnist_corrupted.npz')\n",
    "mnist_train_samples = mnist['x_train']\n",
    "mnist_test_samples = mnist['x_test']\n",
    "train_dataset = DS(mnist_train_samples, train_transforms)\n",
    "val_dataset = DS(mnist_test_samples, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация исходных данных\n",
    "\n",
    "Как и в любой задаче, имеет смысл визуализировать исходные данные, чтобы понимать, с чем мы имеем дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(train_dataset), size=8)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(8, 2), dpi=300)\n",
    "for i, ax in enumerate(axes):\n",
    "    sample_index = indices[i]\n",
    "    sample = train_dataset[sample_index]\n",
    "    ax.imshow(np.squeeze(sample.cpu().numpy()), cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Свёрточный автокодировщик\n",
    "\n",
    "#### Кодировщик (Encoder)\n",
    "Кодировщик можно реализовать в подходе AlexNet или VGG: сверточные (convolutional) слои чередуются со слоями субдискретизации (pooling). Последние применяются для снижения пространственных размерностей промежуточных представлений входных примеров. Нередко после сверточной части добавляют дополнительные полносвязные слои, позволяющие еще сильнее снизить размерность скрытого представления, извлекаемого кодировщиком.\n",
    "\n",
    "Предлагаемая структура кодировщика не единственно верная. Можно реализовывать и другие.\n",
    "\n",
    "#### Декодер\n",
    "\n",
    "Декодер должен преобразовать вектор скрытого представления (тензор ранга 1) в изображение, реконструкцию входного примера. Для этого следует вектор скрытого представления перевести в ранг 2 (например, операцией `.view()`). После этого следует последовательно применять операции Transpose Convolution (`torch.nn.ConvTranspose2d`) и масштабирования (upsampling, а именно `torch.nn.functional.interpolate`). В некоторых случаях применяют `torch.nn.ConvTranspose2d` с аргументом `stride=2` или больше. Однако такое использование может привести в т.н. [\"эффекту шахматной доски\"](https://distill.pub/2016/deconv-checkerboard/). Рекомендуемым вариантом сейчас считается применение масштабирования типа билинейного или бикубического. Во фреймворке Pytorch это преобразование реализовано в форме слоя [`nn.functional.interpolate`](https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html?highlight=interpolate#torch.nn.functional.interpolate), для которого можно задать коэффициент масштабирования (по пространственным переменным) и способ интерполяции (например, `'bicubic'`).\n",
    "\n",
    "Результатом работы декодера должно получиться изображение, по размеру совпадающее с входным примером, то есть, 28x28.\n",
    "\n",
    "Не следует забывать, что одной из целей применения автокодировщиков является снижение размерности примеров с сохранением ключевой информации. Экспериментируйте с количеством слоев и размерностью скрытого представления! Попробуйте снизить его до 2 или вообще до 1. Хорошо ли будут воспроизводиться примеры выборки?\n",
    "\n",
    "В качестве рекомендации можно упомянуть приведение значений в пикселах примеров к диапазону `[0, 1]`. В таком подходе можно на выходе нейросети поставить сигмоидальную функцию активации, которая гладко и дифференцируемо ограничит область значений в этом же диапазоне `[0, 1]`. При этом также можно будет использовать в качестве функции потерь и средний квадрат отклонения [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html), и бинарную перекрестную энтропию [`nn.BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss), и `FocalLoss` (см. реализацию ниже в описании задания)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1:  Описать класс нейросети-автокодировщика, описываемой в этом задании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примечание: рекомендуемая архитектура нейросети\n",
    "\n",
    "Для ускорения исследования может помочь собрать нейросеть следующей архитектуры:\n",
    "\n",
    "```\n",
    "Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "BatchNorm2d(16)\n",
    "Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "BatchNorm2d(32)\n",
    "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "BatchNorm2d(64)\n",
    "Linear(in_features=3136, out_features=1024, bias=True)\n",
    "Linear(in_features=1024, out_features=256, bias=True)\n",
    "BatchNorm1d(256)\n",
    "Linear(in_features=256, out_features=1024, bias=True)\n",
    "Linear(in_features=1024, out_features=3136, bias=True)\n",
    "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "BatchNorm2d(32)\n",
    "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "BatchNorm2d(16)\n",
    "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "BatchNorm2d(16)\n",
    "Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the NN architecture\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        ## слои кодировщика ##\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        ## слои декодера ##\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## применить операции кодировщика ##\n",
    "        \n",
    "        ## применить операции декодера ##\n",
    "        ## На всех скрытых слоях применяйте функцию активации ReLU\n",
    "        ## В случае, если данные отнормированы к диапазону [0,1], активацией последнего слоя может быть sigmoid.\n",
    "        ## Подумайте, какая может быть функция активации в других случаях. Реализуйте подходящий вариант\n",
    "                        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: Напишите пайплайн для предобработки и аугументации данных.\n",
    "\n",
    "В `torchvision.transforms` есть готовые реализации большинства распространённых техник, если вы хотите добавить что-то своё, вы можете воспользоваться `torchvision.transforms.Lambda` или встроить аугментации на этапе подготовки данных в классе `DS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    #YOUR CODE HERE\n",
    "    torchvision.transforms.ToTensor()])\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    #YOUR CODE HERE\n",
    "    torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всегда имеет смысл посмотреть, как происходит предобработка данных, и как происходит обработка данных нейросетью (если это возможно). В этом ДЗ предлагается визуализировать произвольные примеры из обучающей выборки, а также один из произвольных примеров, обработанных только что созданной (но не обученной) моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3: отобразите несколько произвольных примеров обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: отобразите один произвольный пример обучающей выборки, результат вычисления нейросети на этом примере и распределение значений в пикселях реконструированного примера.\n",
    "\n",
    "Распределение значений во всех пикселах реконструкции может помочь понять величину дисперсии ответа нейросети. Напомню, что дисперсия значений в пикселях не должна быть нулевой, то есть, распределение не должно быть похожим на $\\delta$-функцию. Если это так, то следует модифицировать нейросеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = int(np.random.randint(0, len(train_dataset), size=1))\n",
    "example = train_dataset[example_index]\n",
    "\n",
    "## compute model output for this example;\n",
    "## Transfer the result to CPU and convrt it from tensor to numpy array\n",
    "example_transformed = None\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now plot the example and the transformed example\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now plot the distribution of pixel values for the transformed example\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "\n",
    "Теперь, когда вы реализовали модель и подготовили данные, можно приступить к непосредственному обучению модели.\n",
    "\n",
    "Костяк функции обучения написан ниже, далее вы должны будете реализовать ключевые части этого алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
    "                optimizer_params: Dict = {},\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ExponentialLR,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                batch_size = 64,\n",
    "                max_epochs = 100,\n",
    "                early_stopping_patience = 10\n",
    "):\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print(f'Epoch {epoch+1} of {max_epochs}')\n",
    "        train_single_epoch(model, optimizer, loss_function, train_loader)\n",
    "        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n",
    "        print(f'Validation metrics: \\n{val_metrics}')\n",
    "\n",
    "        lr_scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        if best_val_loss is None or best_val_loss > val_metrics['loss']:\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            best_epoch = epoch\n",
    "#             torch.save(model, './best_model.pth')\n",
    "            \n",
    "        if epoch - best_epoch > early_stopping_patience:\n",
    "            print('Early stopping triggered')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5:  Реализуйте функцию, производящую обучение сети на протяжении одной эпохи ( полного прохода по всей обучающей выборке ). На вход будет приходить модель, оптимизатор, функция потерь и объект типа `DataLoader`.\n",
    "> ВНИМАНИЕ!!! В задаче обучения автокодировщика нет меток-цифр. Есть только входные примеры. При итерировании по `data_loader` вы будете получать только сами примеры! Подумайте, что должно выступать в качестве целевой переменной, когда вы вычисляете функцию потерь.\n",
    "\n",
    "### На выходе ожидается словарь с вида:\n",
    "```\n",
    "{\n",
    "    'train_loss': <среднее значение функции потерь за эпоху>\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer, \n",
    "                       loss_function: torch.nn.Module, \n",
    "                       data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    return {'train_loss': test_loss / len(data_loader.dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6:  Реализуйте функцию производящую расчёт функции потерь на тестовой выборке.  На вход будет приходить модель, функция потерь и DataLoader. На выходе ожидается словарь с вида:\n",
    "```\n",
    "{\n",
    "    'val_loss': <среднее значение функции потерь>\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    return {'val_loss': test_loss / len(data_loader.dataset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы корректно реализовали все предыдущие шаги и ваша модель имеет достаточное количество обучаемых параметров, то в следующей ячейке должен пойти процесс обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7: придумайте функцию потерь.\n",
    "\n",
    "Обратите внимание, что в предложенном скелетном коде в ячейке ниже функция потерь по умолчанию прописана неверно (поставлена в `None`). Вы, скорее всего, не сможете обучить автокодировщик с этой функцией потерь. Подумайте, какая должна быть функция потерь при условии, что она должна оценивать качество воспроизведения значений в каждом отдельном пикселе изображения. Впишите в ячейке ниже функцию потерь, которая сработает с условием того, как сформулирована нейросеть.\n",
    "\n",
    "> В наборе данных MNIST чаще всего количество пикселей, в которых значения ненулевые, значительно ниже по сравнению с количеством пикселей со значениями `0`. Если бы стояла задача бинарной классификации пикселей, мы бы воспринимали эту задачу как существенно несбалансированную по классам. Поэтому в случае, если мы воспринимаем значения в пикселях как оценки вероятностей, можно было бы обсудить вопрос, стоит ли применять функцию потерь, характерную для таких задач (бинарную перекрестную энтропию). В качестве альтернативы можно рекомендовать попробовать использовать функцию потерь `FocalLoss`, предложенную в [статье 2017 г.](https://arxiv.org/abs/1708.02002). В ячейке ниже приведена реализация этой функции потерь, подходящая для использования в фреймворке Pytroch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0.25, alpha=2.0, p_th=0.0, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.p_th = p_th\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        tt = torch.cuda.FloatTensor if target.is_cuda else torch.FloatTensor\n",
    "        target_device_bin = (target>self.p_th).type(tt)\n",
    "        pt = pred*target_device_bin + (1-pred)*(1-target_device_bin)\n",
    "        pt = pt+(1e-8)\n",
    "        \n",
    "        ptlog = torch.log(pt)\n",
    "        loss = -self.alpha*ptlog*torch.pow((1-pt), self.gamma)\n",
    "        \n",
    "        if self.size_average:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, \n",
    "            train_dataset=train_dataset, \n",
    "            val_dataset=val_dataset, \n",
    "            loss_function=None, \n",
    "            initial_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка результатов\n",
    "\n",
    "Посмотрите, как ваш обученный автокодировщик преобразует входные примеры. В ячейке ниже приведен код для отображения произвольной пары пример-реконструкция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(np.random.randint(0, len(train_dataset), size=1))\n",
    "sample = train_dataset[index][0]\n",
    "sample_np = np.squeeze(sample.detach().cpu().numpy())\n",
    "sample_ae = model(sample.view(1,1,28,28).to(device))\n",
    "sample_ae_np = np.squeeze(sample_ae.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(4, 2), dpi=200)\n",
    "for i, ax in enumerate(axes):\n",
    "    img = sample_np if i==0 else sample_ae_np\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идентификация аномалий.\n",
    "\n",
    "Идея идентификации аномалий состоит в том, чтобы разделить \"обычные\" экземпляры и \"необычные\" по значению функции потерь автокодировщика на этих примерах. Предполагается, что автокодировщик, обученный на обычных примерах не будет способен достаточно точно воспроизвести необычные примеры. То есть, значение функции потерь на необычных экземплярах будет большим. В этом ДЗ предлагается найти все экземпляры-выбросы, встречающиеся в тестовой выборке, руководствуюясь только значениями функции потерь автокодировщика. Для этого на всех объектах тестовой выборки следует вычислить функцию потерь обученного автокодировщика, и определить, какие экземпляры являются аномальными.\n",
    "\n",
    "В качестве решения всего задания следует получить список значений 0 или 1, соответствующих объектам тестовой выборки. Признак `1` означает, что этот объект является аномалией, `0` - означает, что объект обычный.\n",
    "\n",
    "Например, следующий список `[1,1,1,0,0,0,0,0,0,0,1,0]` означает, что в выборке из 12 объектов тестовой выборки аномалиями считаются первые три и предпоследний. Остальные считаются обычными.\n",
    "\n",
    "> ВНИМАНИЕ! Сопоставление при проверке будет производиться только по номерам объектов в тестовой выборке. Поэтому выборку при вычислении функции потерь не следует перемешивать. То есть, при создании загрузчика данных `torch.utils.data.DataLoader` аргумент перемешивания должен быть выключен: `shuffle=False`\n",
    "\n",
    "### Задание 8: примените обученную модель автокодировщика к данным тестовой выборки. Вычислите функцию потерь на каждом объекте тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_dataset = DS(mnist_test_samples, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "loss_function = None\n",
    "\n",
    "losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader)) as pbar:\n",
    "        for data in test_loader:\n",
    "            ## здесь следует вычислить значения функции потерь для всех элементов тестовой выборки.\n",
    "            curr_loss = 0.0\n",
    "            ## YOUR CODE HERE\n",
    "            \n",
    "            losses.append(curr_loss)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ значений функции потерь\n",
    "Проанализируйте распределение значений функции потерь и найдите объекты, на которых она слишком большая.\n",
    "\n",
    "### Задание 9:\n",
    "- Отобразите гистограмму значений функции потерь. Сделайте выводы (напишите ТЕКСТ) относительно значений для обычных объектов и аномалий.\n",
    "- Найдите объекты-аномалии, отобразите их.\n",
    "- Вычислите на них обученный вами автокодировщик. Отобразите рядом объекты-аномалии и их реконструкцию, вычисленную вашим автокодировщиком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 10: создайте файл маркировки аномалий\n",
    "\n",
    "В этом задании требуется записать в файл признаки аномальности для всех объектов тестовой выборки в том порядке, в котором эти объекты идут в выборке. Это должен быть просто текстовый файл. В нем не должно быть никаких заголовков, никаких дополнительных символов. Только `0` или `1`\n",
    "\n",
    "<br />\n",
    "пример содержимого файла (для выборки длиной 244 объекта, из которых 6 оказались помечены как аномалии):\n",
    "\n",
    "`0000000000000010000000000000000000000000000000000000000000000000000000100000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000001100000000`\n",
    "\n",
    "<br /><br />\n",
    "Финальным решением этого ДЗ является этот файл. Его нужно сдать вместе с ноутбуком с вашим кодом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
