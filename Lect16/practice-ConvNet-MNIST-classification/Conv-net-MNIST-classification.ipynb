{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mish import Mish\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Tuple, List, Type, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import urllib.request\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5(fname):\n",
    "    import hashlib\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(arr):\n",
    "    classes = np.unique(arr)\n",
    "    num_classes = len(classes)\n",
    "    return classes, np.squeeze(np.eye(num_classes)[arr.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие три ячейки предназначены для загрузки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_hash = '84badc3964f15cbf97e9d0cba7f8e6d6'\n",
    "mnist_labels_hash = 'c17778ef9af07481b34bc3ca84d9b21a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('mnist_data.npy'):\n",
    "    print('downloading MNIST data:')\n",
    "    with tqdm(total=100) as pbar:\n",
    "        def show_progress(block_num, block_size, total_size):\n",
    "            cur_perc = block_num * block_size / total_size * 100\n",
    "            pbar.update(cur_perc - pbar.n)\n",
    "        \n",
    "        urllib.request.urlretrieve(\"https://ml4es.ru/links/mnist-data\", \"mnist_data.npy\", show_progress)\n",
    "downloaded_mnist_data_hash = md5('./mnist_data.npy')\n",
    "assert downloaded_mnist_data_hash == mnist_data_hash, 'Downloaded MNIST data is corrupt. Try downloading again.'\n",
    "print('MNIST data is valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('mnist_labels.npy'):\n",
    "    print('downloading MNIST labels:')\n",
    "    with tqdm(total=100) as pbar:\n",
    "        def show_progress(block_num, block_size, total_size):\n",
    "            cur_perc = block_num * block_size / total_size * 100\n",
    "            pbar.update(cur_perc - pbar.n)\n",
    "        \n",
    "        urllib.request.urlretrieve(\"https://ml4es.ru/links/mnist-labels\", \"mnist_labels.npy\", show_progress)\n",
    "downloaded_mnist_labels_hash = md5('./mnist_labels.npy')\n",
    "assert downloaded_mnist_labels_hash == mnist_labels_hash, 'Downloaded MNIST labels is corrupt. Try downloading again.'\n",
    "print('MNIST labels are valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./mnist_data.npy')\n",
    "y = np.load('./mnist_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes,y = one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 28, 28), (70000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X/255.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, X.shape[0], 1)\n",
    "random_digit = X[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(random_digit), cmap='gray')\n",
    "_ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size = (28, 28),\n",
    "                 conv_channels: List[int] = [8, 32, 64],\n",
    "                 activation: Type[torch.nn.Module] = Mish):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        _conv_layers = []\n",
    "        curr_channels = 1\n",
    "        pool = torch.nn.MaxPool2d(kernel_size=(2,2))\n",
    "        for hidden_channels in conv_channels:\n",
    "            conv = torch.nn.Conv2d(curr_channels,\n",
    "                                   hidden_channels,\n",
    "                                   kernel_size=(3,3),\n",
    "                                   stride=1,\n",
    "                                   padding=1,\n",
    "                                   padding_mode='zeros')\n",
    "            _conv_layers.append(conv)\n",
    "            _conv_layers.append(activation())\n",
    "            _conv_layers.append(pool)\n",
    "            curr_channels = hidden_channels\n",
    "        \n",
    "        gap = torch.nn.AvgPool2d(kernel_size=(3,3))\n",
    "        _conv_layers.append(gap)\n",
    "        \n",
    "        _fc_layers = []\n",
    "        _fc_layers.append(torch.nn.Linear(64, 32))\n",
    "        _fc_layers.append(activation())\n",
    "        _fc_layers.append(torch.nn.Linear(32, 16))\n",
    "        _fc_layers.append(activation())\n",
    "        _fc_layers.append(torch.nn.Linear(16, 10))\n",
    "        _fc_layers.append(activation())\n",
    "        \n",
    "        self._conv_layers = torch.nn.Sequential(*_conv_layers)\n",
    "        self._fc_layers = torch.nn.Sequential(*_fc_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self._conv_layers.forward(x)\n",
    "        x = torch.flatten(h, start_dim=1)\n",
    "        out = self._fc_layers.forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer, \n",
    "                       loss_function: torch.nn.Module, \n",
    "                       data_loader: torch.utils.data.DataLoader,\n",
    "                       tb_writer: SummaryWriter,\n",
    "                       epoch: int,\n",
    "                       batch_size: int,\n",
    "                       epoch_size_batches: int):\n",
    "    train_loss = []\n",
    "    batch_averaged_loss = []\n",
    "    idx = 0\n",
    "    model.train()\n",
    "    while True:\n",
    "        (batch_data, batch_labels) = next(iter(data_loader))\n",
    "        optimizer.zero_grad()\n",
    "        data_gpu, labels_gpu = batch_data.cuda(), batch_labels.cuda()\n",
    "        output = model(data_gpu)\n",
    "        loss = loss_function(output, labels_gpu)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        idx = idx + 1\n",
    "        if idx >= epoch_size_batches:\n",
    "            break\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module, \n",
    "                          data_loader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data_gpu, labels_gpu = data.cuda(), labels.cuda()\n",
    "            output = model(data_gpu)\n",
    "            test_loss += loss_function(output, labels_gpu).sum()\n",
    "\n",
    "    return {'loss': test_loss.item() / len(data_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (_conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Mish()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Mish()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): Mish()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): AvgPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0)\n",
      "  )\n",
      "  (_fc_layers): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): Mish()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Mish()\n",
      "    (4): Linear(in_features=16, out_features=10, bias=True)\n",
      "    (5): Mish()\n",
      "  )\n",
      ")\n",
      "Total number of trainable parameters 23690\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('Total number of trainable parameters', \n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None, transform_labels = None):\n",
    "        self.X = X\n",
    "        self.transform = transform\n",
    "        self.Y = y\n",
    "        self.transform_labels = transform_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx, ...][np.newaxis,...]\n",
    "        y = self.Y[idx, ...]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.transform_labels:\n",
    "            y = self.transform_labels(y)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = CustomDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch, ybatch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ВНИМАНИЕ!!!\n",
    "\n",
    "обратить внимание на размерность мини-батча признакового описания объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbatch.shape\n",
    "\n",
    "# Соглашение в Pytorch: признаковое описание примеров поставляется в формате NCHW:\n",
    "# N - нумерует экземпляры (примеры) в подмножестве данных\n",
    "# C - количество цветовых каналов (признаков) во входных данных или в картах активаций\n",
    "# H - высота по пространственным размерностям - кол-во строк\n",
    "# W - ширина по пространственным размерностям - кол-во столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybatch_pred = model(xbatch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybatch_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0951, -0.0501, -0.1182,  0.1460,  0.1087,  0.0802, -0.1054, -0.0611,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1183,  0.1462,  0.1090,  0.0800, -0.1054, -0.0608,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1463,  0.1089,  0.0801, -0.1053, -0.0608,\n",
       "         -0.0867, -0.0342],\n",
       "        [-0.0949, -0.0503, -0.1181,  0.1464,  0.1085,  0.0801, -0.1052, -0.0612,\n",
       "         -0.0865, -0.0343],\n",
       "        [-0.0951, -0.0501, -0.1183,  0.1462,  0.1093,  0.0798, -0.1055, -0.0605,\n",
       "         -0.0866, -0.0345],\n",
       "        [-0.0952, -0.0501, -0.1183,  0.1461,  0.1091,  0.0801, -0.1055, -0.0607,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1463,  0.1087,  0.0802, -0.1052, -0.0612,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0952, -0.0501, -0.1181,  0.1460,  0.1088,  0.0801, -0.1054, -0.0609,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1462,  0.1093,  0.0798, -0.1054, -0.0605,\n",
       "         -0.0866, -0.0344],\n",
       "        [-0.0951, -0.0503, -0.1181,  0.1459,  0.1088,  0.0801, -0.1054, -0.0610,\n",
       "         -0.0867, -0.0343],\n",
       "        [-0.0952, -0.0501, -0.1182,  0.1462,  0.1091,  0.0798, -0.1055, -0.0606,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1183,  0.1462,  0.1093,  0.0799, -0.1054, -0.0605,\n",
       "         -0.0866, -0.0344],\n",
       "        [-0.0949, -0.0503, -0.1184,  0.1463,  0.1092,  0.0801, -0.1053, -0.0607,\n",
       "         -0.0865, -0.0344],\n",
       "        [-0.0951, -0.0502, -0.1183,  0.1461,  0.1089,  0.0802, -0.1054, -0.0608,\n",
       "         -0.0867, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1463,  0.1089,  0.0800, -0.1053, -0.0607,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0951, -0.0501, -0.1182,  0.1461,  0.1090,  0.0800, -0.1055, -0.0608,\n",
       "         -0.0866, -0.0345],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1464,  0.1087,  0.0801, -0.1052, -0.0611,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1463,  0.1091,  0.0800, -0.1053, -0.0606,\n",
       "         -0.0865, -0.0343],\n",
       "        [-0.0951, -0.0503, -0.1182,  0.1461,  0.1086,  0.0802, -0.1053, -0.0609,\n",
       "         -0.0867, -0.0342],\n",
       "        [-0.0951, -0.0501, -0.1183,  0.1461,  0.1095,  0.0800, -0.1055, -0.0604,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0502, -0.1184,  0.1463,  0.1091,  0.0801, -0.1053, -0.0608,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0951, -0.0501, -0.1182,  0.1461,  0.1090,  0.0800, -0.1055, -0.0609,\n",
       "         -0.0865, -0.0345],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1462,  0.1087,  0.0801, -0.1053, -0.0610,\n",
       "         -0.0867, -0.0342],\n",
       "        [-0.0949, -0.0502, -0.1183,  0.1463,  0.1087,  0.0802, -0.1052, -0.0612,\n",
       "         -0.0865, -0.0344],\n",
       "        [-0.0951, -0.0502, -0.1183,  0.1462,  0.1090,  0.0800, -0.1054, -0.0606,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1183,  0.1461,  0.1089,  0.0801, -0.1054, -0.0609,\n",
       "         -0.0866, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1184,  0.1462,  0.1094,  0.0799, -0.1055, -0.0605,\n",
       "         -0.0866, -0.0344],\n",
       "        [-0.0950, -0.0503, -0.1182,  0.1462,  0.1089,  0.0800, -0.1053, -0.0609,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1462,  0.1088,  0.0802, -0.1053, -0.0609,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1182,  0.1463,  0.1085,  0.0803, -0.1052, -0.0612,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0951, -0.0502, -0.1183,  0.1462,  0.1088,  0.0802, -0.1054, -0.0609,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0952, -0.0500, -0.1182,  0.1462,  0.1090,  0.0798, -0.1055, -0.0607,\n",
       "         -0.0866, -0.0346],\n",
       "        [-0.0950, -0.0502, -0.1184,  0.1462,  0.1092,  0.0802, -0.1054, -0.0606,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1462,  0.1086,  0.0802, -0.1053, -0.0612,\n",
       "         -0.0866, -0.0344],\n",
       "        [-0.0951, -0.0501, -0.1182,  0.1461,  0.1091,  0.0800, -0.1055, -0.0607,\n",
       "         -0.0867, -0.0343],\n",
       "        [-0.0950, -0.0502, -0.1184,  0.1462,  0.1092,  0.0800, -0.1054, -0.0607,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0949, -0.0504, -0.1184,  0.1464,  0.1091,  0.0801, -0.1053, -0.0607,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0950, -0.0503, -0.1182,  0.1463,  0.1086,  0.0801, -0.1053, -0.0609,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1184,  0.1463,  0.1092,  0.0802, -0.1053, -0.0607,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0950, -0.0502, -0.1184,  0.1462,  0.1090,  0.0800, -0.1054, -0.0606,\n",
       "         -0.0867, -0.0343],\n",
       "        [-0.0951, -0.0501, -0.1183,  0.1461,  0.1092,  0.0798, -0.1056, -0.0605,\n",
       "         -0.0865, -0.0345],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1463,  0.1088,  0.0800, -0.1053, -0.0610,\n",
       "         -0.0867, -0.0343],\n",
       "        [-0.0951, -0.0501, -0.1181,  0.1461,  0.1086,  0.0803, -0.1053, -0.0610,\n",
       "         -0.0868, -0.0342],\n",
       "        [-0.0949, -0.0503, -0.1181,  0.1464,  0.1085,  0.0801, -0.1051, -0.0612,\n",
       "         -0.0865, -0.0343],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1461,  0.1087,  0.0801, -0.1054, -0.0611,\n",
       "         -0.0866, -0.0344],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1462,  0.1088,  0.0801, -0.1053, -0.0611,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0502, -0.1183,  0.1462,  0.1087,  0.0802, -0.1053, -0.0610,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0949, -0.0503, -0.1183,  0.1464,  0.1090,  0.0799, -0.1053, -0.0608,\n",
       "         -0.0865, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1182,  0.1464,  0.1086,  0.0801, -0.1052, -0.0611,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0950, -0.0501, -0.1183,  0.1462,  0.1090,  0.0803, -0.1054, -0.0609,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0949, -0.0502, -0.1183,  0.1463,  0.1088,  0.0801, -0.1053, -0.0610,\n",
       "         -0.0865, -0.0343],\n",
       "        [-0.0951, -0.0501, -0.1184,  0.1461,  0.1092,  0.0800, -0.1055, -0.0606,\n",
       "         -0.0867, -0.0343],\n",
       "        [-0.0955, -0.0499, -0.1181,  0.1459,  0.1093,  0.0793, -0.1059, -0.0601,\n",
       "         -0.0869, -0.0347],\n",
       "        [-0.0950, -0.0502, -0.1183,  0.1462,  0.1091,  0.0799, -0.1054, -0.0608,\n",
       "         -0.0865, -0.0344],\n",
       "        [-0.0951, -0.0502, -0.1182,  0.1461,  0.1089,  0.0801, -0.1055, -0.0608,\n",
       "         -0.0866, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1183,  0.1462,  0.1089,  0.0801, -0.1053, -0.0607,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0951, -0.0501, -0.1183,  0.1461,  0.1092,  0.0800, -0.1055, -0.0607,\n",
       "         -0.0868, -0.0344],\n",
       "        [-0.0950, -0.0503, -0.1181,  0.1463,  0.1084,  0.0802, -0.1052, -0.0612,\n",
       "         -0.0865, -0.0343],\n",
       "        [-0.0950, -0.0503, -0.1182,  0.1461,  0.1088,  0.0799, -0.1054, -0.0608,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0951, -0.0502, -0.1182,  0.1462,  0.1088,  0.0801, -0.1054, -0.0608,\n",
       "         -0.0867, -0.0344],\n",
       "        [-0.0948, -0.0504, -0.1183,  0.1463,  0.1088,  0.0802, -0.1052, -0.0612,\n",
       "         -0.0865, -0.0342],\n",
       "        [-0.0949, -0.0503, -0.1183,  0.1463,  0.1089,  0.0800, -0.1053, -0.0610,\n",
       "         -0.0865, -0.0344],\n",
       "        [-0.0950, -0.0502, -0.1183,  0.1462,  0.1088,  0.0801, -0.1054, -0.0609,\n",
       "         -0.0866, -0.0342],\n",
       "        [-0.0950, -0.0503, -0.1182,  0.1462,  0.1087,  0.0803, -0.1053, -0.0610,\n",
       "         -0.0867, -0.0342]], device='cuda:0', grad_fn=<Mish_funcBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybatch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3163, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(ybatch_pred, ybatch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name: str,\n",
    "                model: torch.nn.Module, \n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                test_dataloader: torch.utils.data.DataLoader,\n",
    "                loss_function: torch.nn.Module = torch.nn.MSELoss(),\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
    "                optimizer_params: Dict = {},\n",
    "                initial_lr = 0.001,\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                max_epochs = 1000,\n",
    "                early_stopping_patience = 10):\n",
    "    \n",
    "    #region TENSORBOARD tutorial\n",
    "    tb_writer = SummaryWriter(log_dir=f'./logs/{run_name}/')\n",
    "    #endregion ##############################\n",
    "    \n",
    "    #region borrowed from HW03\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "    \n",
    "    best_test_loss = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    loss_history = []\n",
    "    #endregion borrowed from HW03\n",
    "    \n",
    "    pbar = tqdm(total=max_epochs)\n",
    "    for epoch in range(max_epochs):\n",
    "        train_epoch_loss_history = train_single_epoch(model,\n",
    "                                                      optimizer,\n",
    "                                                      loss_function,\n",
    "                                                      train_dataloader,\n",
    "                                                      tb_writer,\n",
    "                                                      epoch,\n",
    "                                                      batch_size=train_dataloader.batch_size,\n",
    "                                                      epoch_size_batches=156)\n",
    "        loss_history = loss_history+train_epoch_loss_history\n",
    "        test_metrics = validate_single_epoch(model,\n",
    "                                             loss_function,\n",
    "                                             test_dataloader)\n",
    "        \n",
    "        #region TENSORBOARD logging\n",
    "        tb_writer.add_scalar('train_loss',\n",
    "                             np.sum(train_epoch_loss_history)/len(train_dataloader.dataset),\n",
    "                             global_step=epoch)\n",
    "        tb_writer.add_scalar('val_loss', test_metrics['loss'], global_step=epoch)\n",
    "        #endregion ##############################\n",
    "        \n",
    "        lr_scheduler.step(test_metrics['loss'])\n",
    "        \n",
    "        if best_test_loss is None or best_test_loss > test_metrics['loss']:\n",
    "            best_test_loss = test_metrics['loss']\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, f'./best_model_{run_name}.pth')\n",
    "        \n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix(ordered_dict={'val_loss': test_metrics['loss']})\n",
    "        #endregion ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:06<00:00,  2.47s/it, val_loss=0.00389]\n"
     ]
    }
   ],
   "source": [
    "train_model('run001',\n",
    "            model, \n",
    "            train_dataloader = train_dataloader,\n",
    "            test_dataloader = val_dataloader,\n",
    "            loss_function=torch.nn.CrossEntropyLoss(), \n",
    "            initial_lr=0.0001,\n",
    "            max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применим нейросеть на одном подмножестве (mini-batch) данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prime = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5677, dtype=torch.float64, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(y_prime, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_class = torch.argmax(y_prime, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 7, 6, 5, 1, 6, 4, 8, 7, 6, 4, 8, 3, 1, 6, 6, 7, 9, 7, 8, 9, 0, 3,\n",
       "        8, 3, 4, 5, 0, 9, 1, 0, 9, 2, 9, 5, 1, 5, 3, 2, 1, 3, 2, 7, 7, 2, 8, 6,\n",
       "        5, 7, 1, 8, 4, 4, 3, 7, 6, 4, 4, 5, 5, 6, 1, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 1, 6, 5, 1, 0, 4, 8, 7, 1, 4, 2, 3, 1, 6, 6, 7, 9, 7, 8, 9, 0, 3,\n",
       "        8, 3, 4, 5, 0, 9, 1, 0, 9, 2, 9, 5, 1, 5, 3, 2, 1, 3, 9, 9, 7, 2, 9, 6,\n",
       "        5, 7, 1, 9, 4, 4, 3, 7, 4, 4, 4, 7, 5, 6, 1, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_class = torch.argmax(y, dim=1)\n",
    "true_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8438)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true_class == output_class).sum()/true_class.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посчитаем долю верных ответов на всем валидационном подмножестве данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:00, 384.38it/s]                                                                                                                                                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "examples_num = 0\n",
    "model.eval()\n",
    "x_batches_test = []\n",
    "y_batches_test = []\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm(val_dataloader, total = len(val_dataset)//64):\n",
    "        x_batches_test.append(x.detach().cpu().numpy())\n",
    "        y_batches_test.append(y.detach().cpu().numpy())\n",
    "        x_gpu, y_gpu = x.cuda(), y.cuda()\n",
    "        output_gpu = model(x_gpu)\n",
    "        output_cpu = output_gpu.cpu()\n",
    "        predicted_class = torch.argmax(output_cpu, dim=1)\n",
    "        true_class = torch.argmax(y, dim=1)\n",
    "        correct = correct + ((true_class == predicted_class).sum()).cpu().detach().numpy()\n",
    "        examples_num = examples_num + float(x.shape[0])\n",
    "        test_loss += loss_function(output_gpu, y_gpu).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.00389288)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = test_loss/examples_num\n",
    "val_loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9295"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy = correct/examples_num\n",
    "val_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
